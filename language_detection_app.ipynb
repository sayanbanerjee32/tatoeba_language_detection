{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d85c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from fastai.text.all import *\n",
    "from fastai.callback.fp16 import *\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "#for download\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f771a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastai_133_langs_v3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for local\n",
    "model_file = 'fastai_133_langs_v3'\n",
    "\n",
    "# for downloading model from gdrive\n",
    "MODEL_URL = \"https://drive.google.com/uc?id=1Qf8ZMbzoEFSGxQ04DOPo01BEcL-43qeu\"\n",
    "gdown.download(MODEL_URL, model_file, quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8540158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# character tokeniser used in fastai to support fastai model loading\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "class CharTokenizer():\n",
    "        \n",
    "    def __call__(self, items):\n",
    "        \n",
    "        # List where I temporarly store the tokens ['xxbos', 'h', 'e', 'l', 'l', 'o', 'xxeos'] as \n",
    "        # they are being parsed.\n",
    "        final_list = []\n",
    "        \n",
    "        # We don't want to mess with the special fastai tokens\n",
    "        special_chars = ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj']\n",
    "        \n",
    "        # Break up string into words, if word in special_chars dont touch it. Otherwise break up each\n",
    "        # word into each character.\n",
    "        for words in items:\n",
    "            tmp = list(flatten([list(word) if word not in special_chars else word \n",
    "                                                for word in words.split()]))\n",
    "            # tmp = []\n",
    "            # for word in words.split():\n",
    "            #     if word not in special_chars:\n",
    "            #         # for char in word:\n",
    "            #         tmp.extend(list(word))\n",
    "            #     else:\n",
    "            #         tmp.append(word)\n",
    "            # tmp has each token 'xxbos', 'xxmaj', 'h', 'e', 'l', 'l', 'o', ',', 'w', 'h', ....]\n",
    "            # We need to put the tmp list into another list to generate a generator below\n",
    "            final_list.append(tmp)\n",
    "        \n",
    "        # Returns a generator\n",
    "        return (t for t in final_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ac901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next 2 lines are for windows\n",
    "# temp = pathlib.PosixPath\n",
    "# pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# next line for linux\n",
    "learner = load_learner(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e79b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipywidgets\n",
    "inp_text = widgets.Text(\n",
    "    placeholder='Type your text',\n",
    "    description='Text:',\n",
    "    disabled=False\n",
    ")\n",
    "lbl_example = widgets.HTML(\n",
    "    value=\"彼の発言で私の希望は失われた。<br/>他的話讓我失去了希望。<br/>His remarks lost my hope.<br/>Ses remarques m'ont fait perdre espoir.<br/>Sus comentarios perdieron mi esperanza.<br/>उनकी टिप्पणियों ने मेरी आशा खो दी।\",\n",
    "    placeholder='Some HTML',\n",
    "    description='Example texts:',\n",
    ")\n",
    "lbl_pred = widgets.Label()\n",
    "lbl_conf = widgets.Label()\n",
    "btn_run = widgets.Button(description='Detect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db067711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger function\n",
    "def on_click_classify(change):\n",
    "    text = inp_text.value.strip()\n",
    "\n",
    "    pred,pred_idx,probs = learner.predict(text)\n",
    "    lbl_pred.value = f'Prediction: {pred}'\n",
    "    lbl_conf.value = f'Confidence: {probs[pred_idx]:.04f}'\n",
    "    attributions, prediction = get_attributions_for_sentence(text)\n",
    "    \n",
    "btn_run.on_click(on_click_classify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5dab78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ef923cf61f4f8db12f34c2b155a6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Detect Language!'), Text(value='彼の発言で私の希望は失われた。', description='Text:', placeholder…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#final layout\n",
    "widgets.VBox([widgets.Label('Detect Language!'), \n",
    "      inp_text, lbl_example, btn_run, \n",
    "      widgets.VBox([lbl_pred,lbl_conf],\n",
    "                 layout={'border': '1px solid black'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e0367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
