{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d85c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import ipyvuetify as v\n",
    "from fastai.text.all import *\n",
    "from fastai.callback.fp16 import *\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "#for download\n",
    "import gdown\n",
    "# for attribution\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f771a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastai_133_langs_v3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for local\n",
    "model_file = 'fastai_133_langs_v3'\n",
    "\n",
    "# for downloading model from gdrive\n",
    "MODEL_URL = \"https://drive.google.com/uc?id=1Qf8ZMbzoEFSGxQ04DOPo01BEcL-43qeu\"\n",
    "gdown.download(MODEL_URL, model_file, quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8540158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# character tokeniser used in fastai to support fastai model loading\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "class CharTokenizer():\n",
    "        \n",
    "    def __call__(self, items):\n",
    "        \n",
    "        # List where I temporarly store the tokens ['xxbos', 'h', 'e', 'l', 'l', 'o', 'xxeos'] as \n",
    "        # they are being parsed.\n",
    "        final_list = []\n",
    "        \n",
    "        # We don't want to mess with the special fastai tokens\n",
    "        special_chars = ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj']\n",
    "        \n",
    "        # Break up string into words, if word in special_chars dont touch it. Otherwise break up each\n",
    "        # word into each character.\n",
    "        for words in items:\n",
    "            tmp = list(flatten([list(word) if word not in special_chars else word \n",
    "                                                for word in words.split()]))\n",
    "            # tmp has each token 'xxbos', 'xxmaj', 'h', 'e', 'l', 'l', 'o', ',', 'w', 'h', ....]\n",
    "            # We need to put the tmp list into another list to generate a generator below\n",
    "            final_list.append(tmp)\n",
    "        \n",
    "        # Returns a generator\n",
    "        return (t for t in final_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ac901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next 2 lines are for windows\n",
    "# temp = pathlib.PosixPath\n",
    "# pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# next line for linux\n",
    "learner = load_learner(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196d94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate attribution for each character\n",
    "def get_attributions_for_sentence(sentence, \n",
    "                                  awd=learner, \n",
    "                                  target = None, \n",
    "                                  lig_n_steps = 200,\n",
    "                                  baseline_token='xxunk'):\n",
    "    # getting to the actual layer that holds embeddings\n",
    "    embedding_layer = awd.model[0]._modules['module']._modules['encoder_dp']\n",
    "\n",
    "    # working around the model prediction - first output only, apply softmax\n",
    "    forward_func = lambda x: torch.softmax(awd.model(x)[0], dim=-1)\n",
    "    \n",
    "    # make integrated gradients instance\n",
    "    lig = LayerIntegratedGradients(\n",
    "        forward_func, \n",
    "        embedding_layer\n",
    "    )\n",
    "    vocab = awd.dls.vocab[0]\n",
    "    num_sentence_tokens = awd.dls.numericalize(sentence).view(1, -1) \n",
    "    sentence_tokens = [vocab[i] for i in num_sentence_tokens[0]]\n",
    "    baseline = torch.ones_like(torch.tensor(num_sentence_tokens)) * vocab.index(baseline_token)\n",
    "    baseline[0,0] = vocab.index('xxbos') # beginning of sentence is always #1\n",
    "    y = awd.predict(sentence)\n",
    "    if target is None:\n",
    "        target = y[1].item()\n",
    "    attrs = lig.attribute(num_sentence_tokens, baseline, target, n_steps=lig_n_steps)\n",
    "    a = attrs.sum(-1)\n",
    "    a = a / torch.norm(a)\n",
    "    return (\n",
    "        pd.Series(a.numpy()[0], index=sentence_tokens),\n",
    "        y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8376613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "class Chip(v.Chip):\n",
    "    positive = '0, 255, 0'\n",
    "    negative = '255, 0, 0'\n",
    "    def __init__(self, word, attribution):\n",
    "        direction = self.positive if attribution >= 0 else self.negative\n",
    "        color = f'rgba({direction}, {abs(attribution):.2f})'\n",
    "        super().__init__(class_='mx-0 px-1', \n",
    "                         children=[word], color=color, \n",
    "                         value=attribution,\n",
    "                         label=True, small=True)\n",
    "        \n",
    "def saliency_chips(attributions:pd.Series) -> v.ChipGroup:\n",
    "    children = [Chip(w, a)\n",
    "           for w, a in attributions.iteritems()]\n",
    "    return v.ChipGroup(column=True, children=children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e79b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipywidgets\n",
    "inp_text = widgets.Text(\n",
    "    placeholder='Type your text',\n",
    "    description='Text:',\n",
    "    disabled=False\n",
    ")\n",
    "# lbl_example = widgets.Label(value='Example text: 彼の発言で私の希望は失われた。')\n",
    "lbl_example = widgets.HTML(\n",
    "    value=\"彼の発言で私の希望は失われた。<br/>他的話讓我失去了希望。<br/>His remarks lost my hope.<br/>Ses remarques m'ont fait perdre espoir.<br/>Sus comentarios perdieron mi esperanza.<br/>उनकी टिप्पणियों ने मेरी आशा खो दी।\",\n",
    "    placeholder='Some HTML',\n",
    "    description='Example texts:',\n",
    ")\n",
    "lbl_pred = widgets.Label()\n",
    "# lbl_conf = widgets.Label()\n",
    "out_pl = widgets.Output()\n",
    "btn_run = widgets.Button(description='Detect & Explain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db067711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger function\n",
    "def on_click_classify(change):\n",
    "    out_pl.clear_output()\n",
    "    lbl_pred.value = ''\n",
    "    text = inp_text.value.strip()\n",
    "    _ = gc.collect()\n",
    "#     pred,pred_idx,probs = learner.predict(text)\n",
    "    \n",
    "#     lbl_conf.value = f'Confidence: {probs[pred_idx]:.04f}'\n",
    "    attributions, prediction = get_attributions_for_sentence(text)\n",
    "    lbl_pred.value = f'Detected language: {prediction[0]}'\n",
    "    with out_pl: display(saliency_chips(attributions))\n",
    "    \n",
    "btn_run.on_click(on_click_classify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5dab78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ef923cf61f4f8db12f34c2b155a6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Detect Language!'), Text(value='彼の発言で私の希望は失われた。', description='Text:', placeholder…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#final layout\n",
    "widgets.VBox([widgets.Label('Detect Language!'), \n",
    "      inp_text, lbl_example, btn_run,\n",
    "#       widgets.VBox([lbl_pred,lbl_conf],\n",
    "#                  layout={'border': '1px solid black'}),\n",
    "      widgets.VBox([lbl_pred,widgets.Label('Attribution...'), out_pl],\n",
    "      layout={'border': '1px solid black'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e0367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
