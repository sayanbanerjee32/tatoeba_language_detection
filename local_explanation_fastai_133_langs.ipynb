{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "local_explanation_fastai_133_langs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1s7RTtl6PmLqiIX41ZegY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/lang_detect/blob/main/local_explanation_fastai_133_langs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D27wqqbnHO9i"
      },
      "source": [
        "%%capture\n",
        "!pip install fastai -Uq\n",
        "!pip install captum\n",
        "!pip install ipyvuetify "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NosqgaQgGhQs",
        "outputId": "4f6071c6-d575-4bde-cde2-9f9c2bf9e479"
      },
      "source": [
        "# mount gdrive for data and model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFa4UptTG3Yu"
      },
      "source": [
        "# model file location\n",
        "saved_model_path = '/content/drive/MyDrive/lang_detection/models/fastai_133_langs_v3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm8EVmMhHGnJ"
      },
      "source": [
        "# support functiosn to load fast ai model\n",
        "from collections.abc import Iterable\n",
        "\n",
        "def flatten(l):\n",
        "    for el in l:\n",
        "        if isinstance(el, Iterable) and not isinstance(el, (str, bytes)):\n",
        "            yield from flatten(el)\n",
        "        else:\n",
        "            yield el\n",
        "class CharTokenizer():\n",
        "        \n",
        "    def __call__(self, items):\n",
        "        \n",
        "        # List where I temporarly store the tokens ['xxbos', 'h', 'e', 'l', 'l', 'o', 'xxeos'] as \n",
        "        # they are being parsed.\n",
        "        final_list = []\n",
        "        \n",
        "        # We don't want to mess with the special fastai tokens\n",
        "        special_chars = ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj']\n",
        "        \n",
        "        # Break up string into words, if word in special_chars dont touch it. Otherwise break up each\n",
        "        # word into each character.\n",
        "        for words in items:\n",
        "            tmp = list(flatten([list(word) if word not in special_chars else word \n",
        "                                                for word in words.split()]))\n",
        "            # tmp has each token 'xxbos', 'xxmaj', 'h', 'e', 'l', 'l', 'o', ',', 'w', 'h', ....]\n",
        "            # We need to put the tmp list into another list to generate a generator below\n",
        "            final_list.append(tmp)\n",
        "        \n",
        "        # Returns a generator\n",
        "        return (t for t in final_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jcHoinyHLpY"
      },
      "source": [
        "# load fastai model\n",
        "from fastai.text.all import *\n",
        "from fastai.callback.fp16 import *\n",
        "learner = load_learner(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-43lgLqHS4O"
      },
      "source": [
        "# getting to the actual layer that holds embeddings\n",
        "embedding_layer = learner.model[0]._modules['module']._modules['encoder_dp']\n",
        "\n",
        "# working around the model prediction - first output only, apply softmax\n",
        "forward_func = lambda x: torch.softmax(learner.model(x)[0], dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtM2DIcvIRs6"
      },
      "source": [
        "from captum.attr import LayerIntegratedGradients\n",
        "# make integrated gradients instance\n",
        "lig = LayerIntegratedGradients(\n",
        "    forward_func, \n",
        "    embedding_layer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6zFUwAbIzrv"
      },
      "source": [
        "# function to get attribution\n",
        "def get_attributions_for_sentence(sentence, \n",
        "                                  awd_model=learner, \n",
        "                                  lig_instance=lig,\n",
        "                                  target = None, \n",
        "                                  lig_n_steps = 200,\n",
        "                                  baseline_token='xxunk'):\n",
        "    awd = awd_model\n",
        "    lig = lig_instance\n",
        "    vocab = awd.dls.vocab[0]\n",
        "    num_sentence_tokens = awd.dls.numericalize(sentence).view(1, -1) \n",
        "    sentence_tokens = [vocab[i] for i in num_sentence_tokens[0]]\n",
        "    baseline = torch.ones_like(torch.tensor(num_sentence_tokens)) * vocab.index(baseline_token) # see \"how to choose a good baseline\"\n",
        "    baseline[0,0] = vocab.index('xxbos') # beginning of sentence is always #1\n",
        "    y = awd.predict(sentence)\n",
        "    if target is None:\n",
        "        target = y[1].item()\n",
        "    attrs = lig.attribute(num_sentence_tokens, baseline, target, n_steps=lig_n_steps)\n",
        "    a = attrs.sum(-1)\n",
        "    a = a / torch.norm(a)\n",
        "    return (\n",
        "        pd.Series(a.numpy()[0], index=sentence_tokens),\n",
        "        y\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "XOBxVYQVJZzZ",
        "outputId": "e2fdedf5-4860-4d44-fe11-265b8f291b26"
      },
      "source": [
        "# generate attribution\n",
        "attributions, prediction = get_attributions_for_sentence('Hi, i am sayan')\n",
        "len(attributions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFjUt7VpeycI"
      },
      "source": [
        "## Create visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I7V3gUZJiOd"
      },
      "source": [
        "import ipyvuetify as v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8liiJRVKXnvV"
      },
      "source": [
        "class Chip(v.Chip):\n",
        "    positive = '0, 255, 0'\n",
        "    negative = '255, 0, 0'\n",
        "    def __init__(self, word, attribution):\n",
        "        direction = self.positive if attribution >= 0 else self.negative\n",
        "        color = f'rgba({direction}, {abs(attribution):.2f})'\n",
        "        super().__init__(class_='mx-0 px-1', \n",
        "                         children=[word], color=color, \n",
        "                         value=attribution,\n",
        "                         label=True, small=True)\n",
        "        \n",
        "def saliency_chips(attributions:pd.Series) -> v.ChipGroup:\n",
        "    children = [Chip(w, a)\n",
        "           for w, a in attributions.iteritems()]\n",
        "    return v.ChipGroup(column=True, children=children)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "9juvMQWnX0qM",
        "outputId": "56043815-fd6a-400a-9837-2e97cfd896e4"
      },
      "source": [
        "print(saliency_chips(attributions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChipGroup(children=[Chip(children=['xxunk'], class_='mx-0 px-1', color='rgba(255, 0, 0, 0.36)', label=True, small=True, value=-0.3613611783949776), Chip(children=['i'], class_='mx-0 px-1', color='rgba(255, 0, 0, 0.40)', label=True, small=True, value=-0.4001495007636005), Chip(children=[','], class_='mx-0 px-1', color='rgba(255, 0, 0, 0.13)', label=True, small=True, value=-0.12803193578127017), Chip(children=['xxunk'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.00)', label=True, small=True, value=0.0), Chip(children=['i'], class_='mx-0 px-1', color='rgba(255, 0, 0, 0.19)', label=True, small=True, value=-0.1946031303840096), Chip(children=['xxunk'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.00)', label=True, small=True, value=0.0), Chip(children=['a'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.07)', label=True, small=True, value=0.06619349642576927), Chip(children=['m'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.07)', label=True, small=True, value=0.06560877550930631), Chip(children=['xxunk'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.00)', label=True, small=True, value=0.0), Chip(children=['s'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.02)', label=True, small=True, value=0.021792684523719432), Chip(children=['a'], class_='mx-0 px-1', color='rgba(255, 0, 0, 0.18)', label=True, small=True, value=-0.18173124278148256), Chip(children=['y'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.50)', label=True, small=True, value=0.5042544049676217), Chip(children=['a'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.60)', label=True, small=True, value=0.5984759845404458), Chip(children=['n'], class_='mx-0 px-1', color='rgba(255, 0, 0, 0.02)', label=True, small=True, value=-0.02006628408604299)], column=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "B8wURi3gX1v-",
        "outputId": "981dce22-ef73-436c-d454-ed5317c46f58"
      },
      "source": [
        "# visualize as bar plot for each character\n",
        "attributions.plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f47c9341690>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWb3wsjzYz_t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}